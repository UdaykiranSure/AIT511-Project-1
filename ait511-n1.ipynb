{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-23T06:55:53.405371Z",
     "iopub.status.busy": "2025-10-23T06:55:53.405047Z",
     "iopub.status.idle": "2025-10-23T06:55:55.551472Z",
     "shell.execute_reply": "2025-10-23T06:55:55.550651Z",
     "shell.execute_reply.started": "2025-10-23T06:55:53.405349Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T06:55:55.553180Z",
     "iopub.status.busy": "2025-10-23T06:55:55.552757Z",
     "iopub.status.idle": "2025-10-23T06:55:55.656208Z",
     "shell.execute_reply": "2025-10-23T06:55:55.655138Z",
     "shell.execute_reply.started": "2025-10-23T06:55:55.553158Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/ait511/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T06:55:55.657523Z",
     "iopub.status.busy": "2025-10-23T06:55:55.657277Z",
     "iopub.status.idle": "2025-10-23T06:55:55.692409Z",
     "shell.execute_reply": "2025-10-23T06:55:55.691571Z",
     "shell.execute_reply.started": "2025-10-23T06:55:55.657502Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T06:55:55.694118Z",
     "iopub.status.busy": "2025-10-23T06:55:55.693837Z",
     "iopub.status.idle": "2025-10-23T06:55:55.740349Z",
     "shell.execute_reply": "2025-10-23T06:55:55.739487Z",
     "shell.execute_reply.started": "2025-10-23T06:55:55.694098Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T06:55:56.100542Z",
     "iopub.status.busy": "2025-10-23T06:55:56.100250Z",
     "iopub.status.idle": "2025-10-23T06:55:56.109097Z",
     "shell.execute_reply": "2025-10-23T06:55:56.108256Z",
     "shell.execute_reply.started": "2025-10-23T06:55:56.100519Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class_dist = df['WeightCategory'].value_counts()\n",
    "class_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T06:56:46.245908Z",
     "iopub.status.busy": "2025-10-23T06:56:46.245102Z",
     "iopub.status.idle": "2025-10-23T06:56:48.078340Z",
     "shell.execute_reply": "2025-10-23T06:56:48.077330Z",
     "shell.execute_reply.started": "2025-10-23T06:56:46.245878Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T06:56:48.080244Z",
     "iopub.status.busy": "2025-10-23T06:56:48.079670Z",
     "iopub.status.idle": "2025-10-23T06:56:48.367380Z",
     "shell.execute_reply": "2025-10-23T06:56:48.366222Z",
     "shell.execute_reply.started": "2025-10-23T06:56:48.080220Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.countplot(data=df, x='WeightCategory', order=df['WeightCategory'].value_counts().index, palette='viridis')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Class Distribution: Weight Categories\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T07:22:18.229775Z",
     "iopub.status.busy": "2025-10-23T07:22:18.228904Z",
     "iopub.status.idle": "2025-10-23T07:22:18.233649Z",
     "shell.execute_reply": "2025-10-23T07:22:18.232813Z",
     "shell.execute_reply.started": "2025-10-23T07:22:18.229746Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "weight_order = [\n",
    "    'Insufficient_Weight',\n",
    "    'Normal_Weight',\n",
    "    'Overweight_Level_I',\n",
    "    'Overweight_Level_II',\n",
    "    'Obesity_Type_I',\n",
    "    'Obesity_Type_II',\n",
    "    'Obesity_Type_III'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T07:22:46.667450Z",
     "iopub.status.busy": "2025-10-23T07:22:46.667138Z",
     "iopub.status.idle": "2025-10-23T07:22:46.912244Z",
     "shell.execute_reply": "2025-10-23T07:22:46.911272Z",
     "shell.execute_reply.started": "2025-10-23T07:22:46.667426Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "sns.countplot(data=df, x='Gender', hue='WeightCategory', hue_order = weight_order, palette='coolwarm')\n",
    "plt.title(\"Gender-wise Obesity Distribution\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T07:23:49.999616Z",
     "iopub.status.busy": "2025-10-23T07:23:49.999276Z",
     "iopub.status.idle": "2025-10-23T07:23:50.839349Z",
     "shell.execute_reply": "2025-10-23T07:23:50.838262Z",
     "shell.execute_reply.started": "2025-10-23T07:23:49.999592Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "num_features = ['Age', 'Height', 'Weight']\n",
    "\n",
    "for col in num_features:\n",
    "    plt.figure(figsize=(8,5))\n",
    "    sns.boxplot(data=df, x='WeightCategory', y=col,order = weight_order, palette='mako')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.title(f\"{col} vs Weight Category\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T07:16:07.247090Z",
     "iopub.status.busy": "2025-10-23T07:16:07.246756Z",
     "iopub.status.idle": "2025-10-23T07:16:07.251357Z",
     "shell.execute_reply": "2025-10-23T07:16:07.250449Z",
     "shell.execute_reply.started": "2025-10-23T07:16:07.247066Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T07:46:17.193565Z",
     "iopub.status.busy": "2025-10-23T07:46:17.192771Z",
     "iopub.status.idle": "2025-10-23T07:46:31.047270Z",
     "shell.execute_reply": "2025-10-23T07:46:31.046260Z",
     "shell.execute_reply.started": "2025-10-23T07:46:17.193537Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "features = ['FCVC', 'NCP', 'CH2O', 'FAF', 'TUE']\n",
    "plt.figure(figsize=(14,8))\n",
    "sns.pairplot(df, vars=features, hue='WeightCategory',hue_order = weight_order, corner=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T07:24:45.184902Z",
     "iopub.status.busy": "2025-10-23T07:24:45.184587Z",
     "iopub.status.idle": "2025-10-23T07:24:46.951096Z",
     "shell.execute_reply": "2025-10-23T07:24:46.950162Z",
     "shell.execute_reply.started": "2025-10-23T07:24:45.184879Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cat_features = ['FAVC','CAEC','CALC','SCC','MTRANS','SMOKE','family_history_with_overweight']\n",
    "\n",
    "for col in cat_features:\n",
    "    plt.figure(figsize=(8,5))\n",
    "    sns.countplot(data=df, x=col, hue='WeightCategory',hue_order = weight_order, palette='Spectral')\n",
    "    plt.title(f\"{col} vs Weight Category\") \n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T07:26:27.565713Z",
     "iopub.status.busy": "2025-10-23T07:26:27.565384Z",
     "iopub.status.idle": "2025-10-23T07:26:27.970797Z",
     "shell.execute_reply": "2025-10-23T07:26:27.969895Z",
     "shell.execute_reply.started": "2025-10-23T07:26:27.565690Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(df.corr(numeric_only=True), annot=True, cmap='coolwarm', center=0)\n",
    "plt.title(\"Numeric Feature Correlations\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T14:39:59.892923Z",
     "iopub.status.busy": "2025-10-26T14:39:59.892515Z",
     "iopub.status.idle": "2025-10-26T14:40:00.378232Z",
     "shell.execute_reply": "2025-10-26T14:40:00.377081Z",
     "shell.execute_reply.started": "2025-10-26T14:39:59.892894Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T14:40:02.304176Z",
     "iopub.status.busy": "2025-10-26T14:40:02.303746Z",
     "iopub.status.idle": "2025-10-26T14:40:02.367271Z",
     "shell.execute_reply": "2025-10-26T14:40:02.366250Z",
     "shell.execute_reply.started": "2025-10-26T14:40:02.304146Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/ait511/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T14:42:15.225328Z",
     "iopub.status.busy": "2025-10-26T14:42:15.225004Z",
     "iopub.status.idle": "2025-10-26T14:42:15.261895Z",
     "shell.execute_reply": "2025-10-26T14:42:15.260599Z",
     "shell.execute_reply.started": "2025-10-26T14:42:15.225307Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Convert boolean columns to integers as they behave like categorical in some contexts\n",
    "bool_cols = df.select_dtypes(include=\"bool\").columns\n",
    "df[bool_cols] = df[bool_cols].astype(int)\n",
    "\n",
    "# Encode categorical columns (object type)\n",
    "cat_cols = df.select_dtypes(include=\"object\").columns\n",
    "for c in cat_cols:\n",
    "    df[c] = df[c].astype(\"category\").cat.codes\n",
    "\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-10-26T16:50:33.819473Z",
     "iopub.status.busy": "2025-10-26T16:50:33.819162Z",
     "iopub.status.idle": "2025-10-26T16:50:39.348422Z",
     "shell.execute_reply": "2025-10-26T16:50:39.347163Z",
     "shell.execute_reply.started": "2025-10-26T16:50:33.819452Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ==============================================\n",
    "# OPTUNA TUNING (No Cross-Validation)\n",
    "# For Gradient Boosting, Random Forest, and KNN\n",
    "# ==============================================\n",
    "\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "# ------------------------------\n",
    "# Load dataset (replace with your own)\n",
    "# ------------------------------\n",
    "\n",
    "feature_names = X.columns\n",
    "target_names = ['WeightCategory']\n",
    "\n",
    "# Main train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Further split training data for validation\n",
    "X_train_sub, X_val, y_train_sub, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
    ")\n",
    "\n",
    "# Scale for KNN\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_sub)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ==========================================================\n",
    "# 1️⃣ Gradient Boosting\n",
    "# ==========================================================\n",
    "def objective_gb(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
    "    }\n",
    "    model = GradientBoostingClassifier(random_state=42, **params)\n",
    "    model.fit(X_train_sub, y_train_sub)\n",
    "    preds = model.predict(X_val)\n",
    "    return accuracy_score(y_val, preds)\n",
    "\n",
    "study_gb = optuna.create_study(direction='maximize', study_name=\"GradientBoosting\")\n",
    "study_gb.optimize(objective_gb, n_trials=5, n_jobs=-1)\n",
    "\n",
    "gb_best_params = study_gb.best_params\n",
    "gb_model = GradientBoostingClassifier(random_state=42, **gb_best_params)\n",
    "gb_model.fit(X_train, y_train)\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "\n",
    "print(\"\\n=== Gradient Boosting Classifier ===\")\n",
    "print(\"Best Params:\", gb_best_params)\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred_gb))\n",
    "print(classification_report(y_test, y_pred_gb, target_names=target_names))\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# 2️⃣ Random Forest\n",
    "# ==========================================================\n",
    "def objective_rf(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 5, 30),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 5),\n",
    "        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', None]),\n",
    "    }\n",
    "    model = RandomForestClassifier(random_state=42, n_jobs=-1, **params)\n",
    "    model.fit(X_train_sub, y_train_sub)\n",
    "    preds = model.predict(X_val)\n",
    "    return accuracy_score(y_val, preds)\n",
    "\n",
    "study_rf = optuna.create_study(direction='maximize', study_name=\"RandomForest\")\n",
    "study_rf.optimize(objective_rf, n_trials=5, n_jobs=-1)\n",
    "\n",
    "rf_best_params = study_rf.best_params\n",
    "rf_model = RandomForestClassifier(random_state=42, n_jobs=-1, **rf_best_params)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "print(\"\\n=== Random Forest Classifier ===\")\n",
    "print(\"Best Params:\", rf_best_params)\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf, target_names=target_names))\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# 3️⃣ K-Nearest Neighbors\n",
    "# ==========================================================\n",
    "def objective_knn(trial):\n",
    "    params = {\n",
    "        'n_neighbors': trial.suggest_int('n_neighbors', 3, 25),\n",
    "        'weights': trial.suggest_categorical('weights', ['uniform', 'distance']),\n",
    "        'metric': trial.suggest_categorical('metric', ['euclidean', 'manhattan']),\n",
    "        'p': trial.suggest_int('p', 1, 2),\n",
    "    }\n",
    "    model = KNeighborsClassifier(**params)\n",
    "    model.fit(X_train_scaled, y_train_sub)\n",
    "    preds = model.predict(X_val_scaled)\n",
    "    return accuracy_score(y_val, preds)\n",
    "\n",
    "study_knn = optuna.create_study(direction='maximize', study_name=\"KNN\")\n",
    "study_knn.optimize(objective_knn, n_trials=5, n_jobs=-1)\n",
    "\n",
    "knn_best_params = study_knn.best_params\n",
    "knn_model = KNeighborsClassifier(**knn_best_params)\n",
    "knn_model.fit(X_train_scaled, y_train)\n",
    "y_pred_knn = knn_model.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\n=== K-Nearest Neighbors Classifier ===\")\n",
    "print(\"Best Params:\", knn_best_params)\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred_knn))\n",
    "print(classification_report(y_test, y_pred_knn, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# =============================\n",
    "# 1) Load data\n",
    "# =============================\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "train = train[:16250]\n",
    "target_col = \"NObeyesdad\"\n",
    "y = train[target_col]\n",
    "X = train.drop(columns=[target_col])\n",
    "test_ids = test[\"id\"]\n",
    "X_test = test.copy()\n",
    "\n",
    "# =============================\n",
    "# 2) Encode features\n",
    "# =============================\n",
    "for df in [X, X_test]:\n",
    "    bool_cols = df.select_dtypes(include=\"bool\").columns\n",
    "    df[bool_cols] = df[bool_cols].astype(int)\n",
    "\n",
    "    cat_cols = df.select_dtypes(include=\"object\").columns\n",
    "    for c in cat_cols:\n",
    "        df[c] = df[c].astype(\"category\").cat.codes\n",
    "\n",
    "# =============================\n",
    "# 3) Encode target\n",
    "# =============================\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# =============================\n",
    "# 4) Stratified K-Fold setup\n",
    "# =============================\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "# =============================\n",
    "# 5) Define objective for Optuna\n",
    "# =============================\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"objective\": \"multi:softprob\",\n",
    "        \"num_class\": len(np.unique(y_encoded)),\n",
    "        \"eval_metric\": \"mlogloss\",\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 4, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0.0, 0.5),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.0, 1.0),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.5, 2.0),\n",
    "        \"seed\": 42,\n",
    "    }\n",
    "\n",
    "    cv_acc = []\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y_encoded)):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y_encoded[train_idx], y_encoded[val_idx]\n",
    "\n",
    "        dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "        dval = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "        bst = xgb.train(\n",
    "            params=params,\n",
    "            dtrain=dtrain,\n",
    "            num_boost_round=400,\n",
    "            evals=[(dval, \"eval\")],\n",
    "            early_stopping_rounds=50,\n",
    "            verbose_eval=False\n",
    "        )\n",
    "\n",
    "        preds = bst.predict(dval)\n",
    "        preds_label = preds.argmax(axis=1)\n",
    "        acc = accuracy_score(y_val, preds_label)\n",
    "        cv_acc.append(acc)\n",
    "\n",
    "    return np.mean(cv_acc)\n",
    "\n",
    "\n",
    "# =============================\n",
    "# 6) Run Optuna tuning\n",
    "# =============================\n",
    "print(\"🔍 Running Optuna tuning (15 trials)...\")\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=15, show_progress_bar=True)\n",
    "\n",
    "print(\"\\n✅ Best params found:\")\n",
    "print(study.best_params)\n",
    "print(f\"Best CV Accuracy: {study.best_value * 100:.2f}%\")\n",
    "\n",
    "best_params = study.best_params\n",
    "best_params.update({\n",
    "    \"objective\": \"multi:softprob\",\n",
    "    \"num_class\": len(np.unique(y_encoded)),\n",
    "    \"eval_metric\": \"mlogloss\",\n",
    "    \"seed\": 42\n",
    "})\n",
    "\n",
    "# =============================\n",
    "# 7) Train final model with best params\n",
    "# =============================\n",
    "test_pred_prob = np.zeros((len(X_test), len(np.unique(y_encoded))))\n",
    "oof_preds = np.zeros((len(X), len(np.unique(y_encoded))))\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y_encoded)):\n",
    "    print(f\"\\n===== Fold {fold + 1} =====\")\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y_encoded[train_idx], y_encoded[val_idx]\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dval = xgb.DMatrix(X_val, label=y_val)\n",
    "    dtest = xgb.DMatrix(X_test)\n",
    "\n",
    "    evals = [(dtrain, \"train\"), (dval, \"eval\")]\n",
    "\n",
    "    bst = xgb.train(\n",
    "        params=best_params,\n",
    "        dtrain=dtrain,\n",
    "        num_boost_round=1000,\n",
    "        evals=evals,\n",
    "        early_stopping_rounds=100,\n",
    "        verbose_eval=100\n",
    "    )\n",
    "\n",
    "    best_iter = bst.best_iteration or 1000\n",
    "    oof_pred_prob = bst.predict(dval, iteration_range=(0, best_iter))\n",
    "    test_pred_prob += bst.predict(dtest, iteration_range=(0, best_iter)) / skf.n_splits\n",
    "    oof_preds[val_idx] = oof_pred_prob\n",
    "\n",
    "    # Add classification report for validation data\n",
    "    oof_pred_labels_fold = oof_pred_prob.argmax(axis=1)\n",
    "    print(f\"\\nClassification Report for Fold {fold + 1}:\")\n",
    "    print(classification_report(y_val, oof_pred_labels_fold, target_names=le.classes_))\n",
    "\n",
    "\n",
    "# =============================\n",
    "# 8) Evaluate OOF Accuracy\n",
    "# =============================\n",
    "oof_pred_labels = oof_preds.argmax(axis=1)\n",
    "cv_acc = accuracy_score(y_encoded, oof_pred_labels)\n",
    "print(f\"\\nFinal OOF CV Accuracy: {cv_acc * 100:.2f}%\")\n",
    "\n",
    "# =============================\n",
    "# 9) Save submission\n",
    "# =============================\n",
    "y_test_pred = test_pred_prob.argmax(axis=1)\n",
    "y_test_labels = le.inverse_transform(y_test_pred)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"id\": test_ids,\n",
    "    \"WeightCategory\": y_test_labels\n",
    "})\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(\"\\n submission.csv saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8552525,
     "sourceId": 13472618,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
